{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden layer weights before:\n",
      "[[-0.01036466 -0.00265865  0.01167249]\n",
      " [ 0.02834345  0.0065195  -0.0131811 ]\n",
      " [ 0.00890789  0.01111226  0.00455793]\n",
      " [-0.01750345 -0.00285416 -0.00074511]]\n",
      "Output layer weights before:\n",
      "[[ 0.01266575 -0.0002214   0.00263722 -0.02280468]]\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.3010190638832428\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.2953546401878497\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.2910163282912544\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.2876894179304417\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.2851333212392633\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.28316491721063414\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.28164507028527114\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.2804680578073599\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.27955343712270264\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.2788398604563921\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.27828040032678625\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.27783902617284245\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.2774879493876075\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.27720561968430685\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.2769752085893214\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.2767834568419692\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.27661979357789085\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.27647565846905026\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.27634397531991833\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.2762187384585251\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.27609468276279453\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.2759670151984966\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.2758311909679701\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.2756827212655319\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.2755170025713523\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.2753291596680712\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.27511389634991573\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.27486534928781253\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.2745769418652453\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.2742412361424204\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.27384978256629494\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.2733929687404004\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.27285987061037437\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.27223811189657404\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.27151374056009986\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.2706711344961863\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.2696929523699873\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.26856014925073474\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.26725207998216377\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.26574671538500105\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.2640209966200177\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.2620513505172185\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.2598143826765525\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.25728775515446173\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.2544512412364155\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.2512879308404574\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.24778553607806988\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.2439377172559732\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.23974531654175027\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.23521735471325844\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.2303716261902418\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.2252347332585257\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.2198414448704835\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.21423335153296894\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.20845690223013888\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.20256102371393814\n",
      "Predicted labels:[[1. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.19659460337609005\n",
      "Predicted labels:[[0. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.19060413948883806\n",
      "Predicted labels:[[0. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.18463182075692183\n",
      "Predicted labels:[[0. 1. 1.]] Actual labels:[[0 1 1]]\n",
      "cost 0.17871420497643029\n",
      "Hidden layer Weight after logistic regression:\n",
      "[[-0.03104943  0.14539836 -0.1514061 ]\n",
      " [-0.02116653  0.42374841 -0.46429183]\n",
      " [-0.03413379  0.32867573 -0.3464898 ]\n",
      " [ 0.03183714 -0.77374269  0.78113862]]\n",
      "Output layer Weight after logistic regression:\n",
      "[[ 0.21330296  0.64612284  0.48694893 -1.18389365]]\n",
      "Hidden layer Bias after logistic regression:\n",
      "[[ 0.01868983]\n",
      " [ 0.06337749]\n",
      " [ 0.04090847]\n",
      " [-0.17194924]]\n",
      "Output layer Bias after logistic regression:\n",
      "[[0.75733673]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(30)\n",
    "\n",
    "# Defining inputs(X) with their labels(y)\n",
    "x = np.random.rand(3,3)\n",
    "y = np.array([0,1,1])\n",
    "y = y.reshape(1,3)\n",
    "m = y.size #Number of training examples\n",
    "\n",
    "# Initializing weights, bias for hidden layer\n",
    "w1 = np.random.randn(4,3) * 0.01\n",
    "print('Hidden layer weights before:')\n",
    "print(w1)\n",
    "b1 = np.zeros((4,1))\n",
    "\n",
    "# Initializing weights, bias  for output layer\n",
    "w2 = np.random.randn(1,4) * 0.01\n",
    "print('Output layer weights before:')\n",
    "print(w2)\n",
    "b2 = 0\n",
    "\n",
    "# Set learning rate and number of iterations\n",
    "lr = 0.5\n",
    "iterations = 60\n",
    "\n",
    "for i in range(iterations):\n",
    "    # Function to predict (Not in binary form), hidden layer\n",
    "    z1 = np.dot(w1, x) + b1 \n",
    "    \n",
    "    # Predicted y hat (applying the tanh activation function), hidden layer\n",
    "    a1 = (np.exp(z1)-np.exp(-z1)) / (np.exp(z1)+np.exp(-z1))\n",
    "    \n",
    "    da1 = 1 - np.square((np.tanh(z1))) # derivative of tanh activation function\n",
    "\n",
    "    # 2nd layer with sigmoid activation function\n",
    "    z2 = np.dot(w2, a1) + b2\n",
    "    a2 = 1 / (1 + np.exp(-z2))\n",
    "    \n",
    "    da2 = (a2 * (1-a2))\n",
    "    print('Predicted labels:' + str(np.round(a2)), 'Actual labels:' + str(y))\n",
    "    \n",
    "    # Calculating the loss\n",
    "    loss = -(y * np.log10(a2) + (1-y) * np.log10(1-a2))\n",
    "\n",
    "    # Calculating the cost function\n",
    "    cost = (np.sum(loss))/(m)\n",
    "    print('cost', cost)\n",
    "\n",
    "    # Gradient descent\n",
    "    dz2 = np.subtract(a2, y) #dz2 = ((-y/a2) + ((1-y)/(1-a2))) * (da2) alternative way of getting dz2\n",
    "    \n",
    "    dw2 = np.dot(dz2, a1.T)/(m)\n",
    "    \n",
    "    db2 = (np.sum(dz2, axis=1, keepdims = True))/m\n",
    "    \n",
    "    dz1 = (np.dot(w2.T,dz2)) * (da1)\n",
    "    \n",
    "    dw1 = np.dot(dz1, x.T)/(m)\n",
    "    \n",
    "    db1 = (np.sum(dz1, axis=1, keepdims = True))/m\n",
    "\n",
    "    # Updating weights and bias\n",
    "    w1 = w1 - np.dot(lr, dw1)\n",
    "    b1 = b1 - np.dot(lr, db1)\n",
    "    w2 = w2 - np.dot(lr, dw2)\n",
    "    b2 = b2 - np.dot(lr, db2)\n",
    "    \n",
    "print('Hidden layer Weight after logistic regression:')\n",
    "print(w1)\n",
    "print('Output layer Weight after logistic regression:')\n",
    "print(w2)\n",
    "print('Hidden layer Bias after logistic regression:',)\n",
    "print(b1)\n",
    "print('Output layer Bias after logistic regression:',)\n",
    "print(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
